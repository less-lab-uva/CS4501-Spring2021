---
title: Lab E
subtitle: Robotics and Ethics
layout: page
---

# Robotics and Ethics

[Ethics](https://plato.stanford.edu/entries/ethics-ai/) -- the moral principles that govern a person's conduct or engagement in an activity -- 
and its role in tech is becoming a more widely and contentiously debated topic.
[Robotics often sits at the heart of that debate](https://spectrum.ieee.org/automaton/robotics/artificial-intelligence/study-shows-that-humans-attribute-morals-and-emotions-to-robots) because it’s a highly experimental field, 
full of emerging technology from “internet of things“ to “AI”, 
and lends itself to open-ended development with tons of room for growth accompanied by unclear social-economical implications for the future.


For example, consider the following question: should we keep full autonomy out of the reach of robots? 
On one hand, if the autonomous capabilities in question involve high levels of risk, such as using deadly force or making impactful decisions about quality of life, full autonomy may be deemed too difficult of a task to automate correctly.
On the other hand, it could be deemed worth the risk if it protects others from physical harm. Answering such a question requires a deep understanding of the context in which the question is posed, the factors to be considered, and a systematic study of the implications of each potential answer under multiple and often uncertain scenarios. 

Given the relevance of ethics to robotics and closely related fields, in this lab we will explore a series of technical scenarios with inherent ethical problems, take a position, and develop arguments to support those positions.


# Learning Objectives

At the end of this lab, you should understand:
* How to synthesize meaningful questions from situations that present ethical problems.
* How to find and use related work that informs these questions.
* How to connect the current state of the art to possible future scenarios and their implications. 
* How to participate in debating ethical questions in a respectful productive way.

{% include notification.html message="Submission: The checkpoints are handled a little differently for this lab. The first checkpoint consist of a  written document that must be submitted via Collab before class on March 18th. The second checkpoint is the actual in-class debate on March 18th." 
status="is-success" 
icon="fas fa-exclamation-triangle" %}

#  Activity

The lab is divided in two parts: **Preparation** and **Debate**.

**Preparation.**
Start by forming a team with another class member (teams of 2) and pick one of the **prompts** provided in the next section. Then, your team must pick a side -- affirmative or negative -- and begin to build an argument around that position (more details on building the argument are found later in this doc).

Signup for teams, prompts, and affirmative/negative positions are available at [this google spreadsheet](https://docs.google.com/spreadsheets/d/14P6ccK_N2kmGguAlfEjwIMGkgzYyUN1Uk8nzB8UJiyc/edit?usp=sharing). Signup is on a first come, first serve basis so sign up quickly if you see a prompt you really like.
Note that teams on opposite positions of the same prompt will be debating against each other.

For example, let's say my team chooses a prompt like "Should businesses be allowed to make companionship robots for widespread commercial production?", and the position that I've chosen is affirmative; i.e. I've answered the question with a "Yes, they should be allowed to."
We would then look for sources to support  the positive  effects of having a companionship robot on the individual who buys one. For example, I might look at [social robots for the elderly](https://www.vox.com/future-perfect/2020/9/9/21418390/robots-pandemic-loneliness-isolation-elderly-seniors) and [interactive sex robots](https://www.forbes.com/sites/bernardmarr/2020/11/30/future-of-intimacy-sex-bots-virtual-reality-and-smart-sex-toys/?sh=39b5af7738fa) for those who struggle with intimacy, as well as what [healthcare professionals see as the benefits and drawbacks](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6719485/) of using them.
Then, I would point to possible future contexts in which the benefits and drawbacks of today might be amplified or fundamentally shifted, like the isolated, space-dwelling humans' relationships with their androids in Philip K. Dick's *[Do Androids Dream of Electric Sheep?](https://www.nature.com/articles/d41586-018-02695-7)*. 

**Debate.**
On the day of the lab, teams on opposite sides of the same prompt will debate each other and a winner will be chosen by the audience.
*Winning your debate won't affect your ability to earn a 100% on this lab (the lab is worth 5 points), but it will earn you one extra credit point towards your lab grade.*
Each debate will have 11 minutes with the time split evenly between teams and  a moderator to keep track of time (more details are provided below).




## Prompts

The prompts to choose from are:
1. Should [moral machines](https://www.media.mit.edu/publications/moral-machine-perception-of-moral-judgment-made-by-machines/) drive the analysis of risk when human life is involved? 
2. Should drivers have to take [alertness tests in order to use autonomous cars](https://www.nytimes.com/2019/03/28/business/autonomous-cars-technology-privacy.html), such as "alertness breathalyzers" to start the car or continuous monitoring of their eye movements?
3. Should a [caretaking/personal assistant robot](https://ieeexplore.ieee.org/abstract/document/5980058?casa_token=V_F525cBorwAAAAA:3_PgIxa4xJ2ne9vSWF_hKAGK6s7JrADljtNiuG42-5ZjcNPGjiZYGvAmDMk3YlOxgMha85uv) have control over the daily activities of their human (food, medicine, exercise, bedtime/waking time, etc.)? 
4. Should it be a war crime to [remotely operate robots that are equipped with the capability to use deadly force](https://dc.law.utah.edu/cgi/viewcontent.cgi?article=1047&context=ulr)?
5. Should the [right to repair](https://www.nytimes.com/2020/10/23/climate/right-to-repair.html) be available to everyone, if it means compromising potentially safety-critical systems?


## Gathering Sources to Build your Argument
 
We have provided a single source for you to help pick your topic and get started with your research, but you will need to incorporate more sources to understand your topic and formulate your argument. You can use as many additional sources as you need to support your position. To show that you have a well-informed position on the topic, you will need to do some background research and critical thinking about the sources you find. 

In the outline required for *Checkpoint 1* you must cite and include a variety of  sources that contribute to your argument. Here are the source types required with examples for the illustration prompt we mentioned earlier "Should businesses be allowed to make companionship robots for widespread commercial production?”:

1. At least two news articles that characterize the ways in which the target problem is present today.  Examples of this   might be the Vox article on [social robots for the elderly](https://www.vox.com/future-perfect/2020/9/9/21418390/robots-pandemic-loneliness-isolation-elderly-seniors) and the Forbes article on [interactive sex robots](https://www.forbes.com/sites/bernardmarr/2020/11/30/future-of-intimacy-sex-bots-virtual-reality-and-smart-sex-toys/?sh=39b5af7738fa) mentioned earlier.

2. At least one peer-reviewed writing such as a research article, journal, or book on ethics/fairness/discrimination in a field related to your prompt to back up your debate position. An example of this might be the [NIH study on what healthcare professionals see as the benefits and drawbacks of companion robots](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6719485/) mentioned earlier.

3. One motivating example that is either from an anecdotal account, or that has enough documented support to be a believably common occurrence. An example of this could be this human interest story from MIT on [sending robots to libraries to read to underprivileged children](https://www.media.mit.edu/projects/collaborative-robot-storyteller/overview/).

4. One **well-known** sci-fi/futuristic work of fiction that incorporates robots to use as a framing device for the future consequences or implications of the position you or your opponent may take on the prompt.   Favor  ones with which your audience may be familiar. For example, we might assume that most people have seen *2001: A Space Odyssey* and are passingly familiar with the concept of a robot controlling a space ship, but most people are not familiar with the Kubrickian interpretation of the ending in which the main character is supposedly held captive in an alien zoo. 
In the context of companion robots, a good choice of sci-fi could be Philip K. Dick's *[Do Androids Dream of Electric Sheep?](https://www.nature.com/articles/d41586-018-02695-7)* or "Dolores", the robot host from the 2016 reprise of TV series *[Westworld](https://www.imdb.com/title/tt0475784/)*. 
    
Think about your audience and plan carefully as you choose your source material, building them to address the questions of Checkpoint 1 (see below).  

You must cite (but not plagiarize) the research and arguments of others when building your related work.  


## Outlining Your Argument

When organizing your argument, you will have stronger and weaker points. Make sure your argument has a logical flow. 
Arguments are often organized according to points that the audience can easily agree with.
Getting audience "buy-in" early on can help when leading them along to your more complicated or difficult-to-accept arguments.

For example, there are lots of ways to structure an argument for an affirmative position to my example question "Should people be using companion robots en masse?". 
What's important is that I have solid reasons for why certain arguments are more compelling.
Let's say I have three arguments prepared:

<ol>
<li>Companion robots improve the quality of life for lots of people, the ones that they affect directly and many others that they affect indirectly. 
    <ol type="I">
    <li>Companion robots free up counselors and therapists to work on more complex problems.</li>
    <li>Companion robots help those with social and sexual disorders gain confidence, resulting in stronger human-to-human relationships. </li>
    </ol>
</li>
<li>Companion robots are excellent way to introduce robots into society and improve public opinion about robots.</li>
<li>Companion robots strengthen the economy and create jobs.</li>
</ol>

I've organized them this way because I believe I can confidently argue that the well-being of humans is the highest priority and the main purpose of companion robots, as well as an easy priority for much of my audience. That main point is followed by weaker points that I believe less people will think are important -- social opinion of robots and the health of the economy. 

Additionally, keep in mind the potential counterarguments. Acknowledging your opponent's points shows that you have a well thought out, 
comprehensive position and disarms your opponent ahead of time.
The negative position towards my example question might argue that companion robots might, through poor programming, hurt the people they are meant to be helping. 
Anticipating that, I might include a point in my argument that a companion robot only has the capabilities we equip it with, and its size and shape could be constrained to be light enough to be lifted by a human or to be made of only soft, bouncy materials that cannot dam
